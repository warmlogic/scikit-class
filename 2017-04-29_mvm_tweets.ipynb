{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%load_ext autoreload\n",
    "# \"1\" means: always reload modules marked with \"%aimport\"\n",
    "# \"2\" means: always reload all modules except those marked with \"%aimport\"\n",
    "%autoreload 1\n",
    "\n",
    "# from __future__ import absolute_import, division, print_function\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib as mpl\n",
    "# from matplotlib.pyplot import GridSpec\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# import warnings\n",
    "\n",
    "# sns.set_context(\"poster\", font_scale=1.3)\n",
    "# sns.set_context(\"notebook\", font_scale=1.0)\n",
    "\n",
    "# pd.set_option('display.max_columns', 100)\n",
    "# pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example for adding path\n",
    "# write code in ../src and add that to runtime path\n",
    "# src_dir = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "# sys.path.append(src_dir)\n",
    "\n",
    "# Import like so\n",
    "# # import my_module from the source directory\n",
    "# %aimport my_module\n",
    "# from my_module.build_features import remove_invalid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9093, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@teachntech00 New iPad Apps For #SpeechTherapy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#SXSW is just starting, #CTIA is around the co...</td>\n",
       "      <td>Android</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Beautifully smart and simple idea RT @madebyma...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Counting down the days to #sxsw plus strong Ca...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "5  @teachntech00 New iPad Apps For #SpeechTherapy...   \n",
       "6                                                NaN   \n",
       "7  #SXSW is just starting, #CTIA is around the co...   \n",
       "8  Beautifully smart and simple idea RT @madebyma...   \n",
       "9  Counting down the days to #sxsw plus strong Ca...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "5                             NaN   \n",
       "6                             NaN   \n",
       "7                         Android   \n",
       "8              iPad or iPhone App   \n",
       "9                           Apple   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  \n",
       "5                 No emotion toward brand or product  \n",
       "6                 No emotion toward brand or product  \n",
       "7                                   Positive emotion  \n",
       "8                                   Positive emotion  \n",
       "9                                   Positive emotion  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text                                               1\n",
       "emotion_in_tweet_is_directed_at                       5802\n",
       "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['tweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fixed_text = df['tweet_text']\n",
    "\n",
    "fixed_target = df['is_there_an_emotion_directed_at_a_brand_or_product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9092,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CountVectorizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(fixed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9706"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8562\n"
     ]
    }
   ],
   "source": [
    "print(count_vect.vocabulary_.get(u'the'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n"
     ]
    }
   ],
   "source": [
    "print(count_vect.vocabulary_.get(u'3g'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = count_vect.transform(fixed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    .@wesley83 I have a 3G iPhone. After 3 hrs twe...\n",
      "1    @jessedee Know about @fludapp ? Awesome iPad/i...\n",
      "Name: tweet_text, dtype: object\n",
      "  (0, 168)\t1\n",
      "  (0, 430)\t1\n",
      "  (0, 774)\t2\n",
      "  (0, 2291)\t1\n",
      "  (0, 3981)\t1\n",
      "  (0, 4210)\t1\n",
      "  (0, 4573)\t1\n",
      "  (0, 4610)\t1\n",
      "  (0, 5766)\t1\n",
      "  (0, 6478)\t1\n",
      "  (0, 7232)\t1\n",
      "  (0, 8076)\t1\n",
      "  (0, 8323)\t1\n",
      "  (0, 8702)\t1\n",
      "  (0, 8920)\t1\n",
      "  (0, 9062)\t1\n",
      "  (0, 9303)\t1\n",
      "  (0, 9373)\t1\n",
      "  (1, 313)\t1\n",
      "  (1, 527)\t1\n",
      "  (1, 644)\t1\n",
      "  (1, 677)\t1\n",
      "  (1, 774)\t1\n",
      "  (1, 876)\t1\n",
      "  (1, 2386)\t1\n",
      "  (1, 3356)\t1\n",
      "  (1, 3401)\t1\n",
      "  (1, 3454)\t1\n",
      "  (1, 3685)\t1\n",
      "  (1, 4560)\t1\n",
      "  (1, 4573)\t1\n",
      "  (1, 4619)\t1\n",
      "  (1, 4678)\t1\n",
      "  (1, 4847)\t1\n",
      "  (1, 5042)\t1\n",
      "  (1, 5094)\t1\n",
      "  (1, 6913)\t1\n",
      "  (1, 8323)\t1\n",
      "  (1, 8560)\t1\n",
      "  (1, 8602)\t1\n",
      "  (1, 8870)\t1\n",
      "  (1, 9625)\t1\n"
     ]
    }
   ],
   "source": [
    "print(fixed_text[0:2])\n",
    "print(counts[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in count_vect.vocabulary_.items():\n",
    "#     if v == 774:\n",
    "#         print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8404)\t1\n"
     ]
    }
   ],
   "source": [
    "print(count_vect.transform(['tacos']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(counts, fixed_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive emotion']\n"
     ]
    }
   ],
   "source": [
    "print(nb.predict(count_vect.transform([\"i love my iphone\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive emotion']\n"
     ]
    }
   ],
   "source": [
    "print(nb.predict(count_vect.transform([\"this sucks\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Negative emotion']\n"
     ]
    }
   ],
   "source": [
    "print(nb.predict(count_vect.transform([\"sucks\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Negative emotion']\n"
     ]
    }
   ],
   "source": [
    "print(nb.predict(count_vect.transform([\"iphone does not suck\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Negative emotion']\n"
     ]
    }
   ],
   "source": [
    "print(nb.predict(count_vect.transform([\"iphone costs\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Negative emotion']\n"
     ]
    }
   ],
   "source": [
    "# print(nb.predict(count_vect.transform([\"iphone!!!\"])))\n",
    "print(nb.predict(count_vect.transform([\"iphone costs too much!!!\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795094588649\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(counts, fixed_target)\n",
    "\n",
    "predictions = nb.predict(counts)\n",
    "correct = sum(predictions == fixed_target)\n",
    "incorrect = sum(predictions != fixed_target)\n",
    "acc = correct/float(len(fixed_target))\n",
    "\n",
    "print(correct)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9092, 9706)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on 6365 examples (70.0%)\n",
      "testing on 2727 examples\n"
     ]
    }
   ],
   "source": [
    "prop_train = 0.7\n",
    "n_train = int(np.ceil(fixed_target.shape[0] * prop_train))\n",
    "print('training on {} examples ({:.1%})'.format(n_train, prop_train))\n",
    "print('testing on {} examples'.format(fixed_target.shape[0] - n_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1805\n",
      "0.661899523286\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(counts[:n_train], fixed_target[:n_train])\n",
    "\n",
    "predictions = nb.predict(counts[n_train:])\n",
    "correct = sum(predictions == fixed_target[n_train:])\n",
    "acc = correct/float(len(fixed_target[n_train:]))\n",
    "\n",
    "print(correct)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1667\n",
      "0.61129446278\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "nb = DummyClassifier(strategy='most_frequent')\n",
    "nb.fit(counts[:n_train], fixed_target[:n_train])\n",
    "\n",
    "predictions = nb.predict(counts[n_train:])\n",
    "correct = sum(predictions == fixed_target[n_train:])\n",
    "acc = correct/float(len(fixed_target[n_train:]))\n",
    "\n",
    "print(correct)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.65824176  0.63076923  0.60659341  0.60879121  0.64395604  0.68901099\n",
      "  0.70077008  0.66886689  0.65270121  0.62183021]\n",
      "0.648153102333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "scores = cross_val_score(nb, counts, fixed_target, cv=10)\n",
    "print(scores)\n",
    "print(scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.59230769  0.59230769  0.59230769  0.59230769  0.59230769  0.59230769\n",
      "  0.5929593   0.5929593   0.59316428  0.59316428]\n",
      "0.592609330138\n",
      "['No emotion toward brand or product']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "nb = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "scores = cross_val_score(nb, counts, fixed_target, cv=10)\n",
    "\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "nb.fit(counts, fixed_target)\n",
    "print(nb.predict(count_vect.transform([\"love I my iphone!!!\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive emotion']\n",
      "9706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "p = Pipeline(steps=[('counts', CountVectorizer()),\n",
    "                ('multinomialnb', MultinomialNB())])\n",
    "\n",
    "p.fit(fixed_text, fixed_target)\n",
    "print(p.predict([\"I love my iphone!\"]))\n",
    "\n",
    "print(len(p.named_steps['counts'].vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59614\n"
     ]
    }
   ],
   "source": [
    "p = Pipeline(steps=[('counts', CountVectorizer(ngram_range=(1, 2))),\n",
    "                ('multainomialnb', MultinomialNB())])\n",
    "\n",
    "p.fit(fixed_text, fixed_target)\n",
    "#print(p.named_steps['counts'].vocabulary_.get(u'garage sale'))\n",
    "print(len(p.named_steps['counts'].vocabulary_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.68351648  0.66593407  0.65384615  0.64725275  0.68021978  0.69120879\n",
      "  0.73267327  0.70517052  0.68026461  0.64829107]\n",
      "0.678837748442\n"
     ]
    }
   ],
   "source": [
    "p = Pipeline(steps=[('counts', CountVectorizer(ngram_range=(1, 2))),\n",
    "                ('multinomialnb', MultinomialNB())])\n",
    "\n",
    "p.fit(fixed_text, fixed_target)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(p, fixed_text, fixed_target, cv=10)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.67032967  0.66813187  0.62087912  0.64285714  0.64945055  0.67912088\n",
      "  0.67876788  0.6809681   0.66041896  0.63947078]\n",
      "0.659039495078\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "p = Pipeline(steps=[('counts', CountVectorizer(ngram_range=(1, 2))),\n",
    "                ('feature_selection', SelectKBest(chi2, k=10000)),\n",
    "                ('multinomialnb', MultinomialNB())])\n",
    "\n",
    "p.fit(fixed_text, fixed_target)\n",
    "\n",
    "scores = cross_val_score(p, fixed_text, fixed_target, cv=10)\n",
    "print(scores)\n",
    "print(scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.605\n",
      "Best parameters set:\n",
      "\tcounts__max_df: 0.5\n",
      "\tcounts__min_df: 3\n",
      "\tcounts__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "p = Pipeline(steps=[('counts', CountVectorizer()),\n",
    "                ('feature_selection', SelectKBest(chi2)),\n",
    "                ('multinomialnb', MultinomialNB())])\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'counts__max_df': (0.5, 0.75, 1.0),\n",
    "    'counts__min_df': (1, 2, 3),\n",
    "    'counts__ngram_range': ((1,1), (1,2)),\n",
    "#    'feature_selection__k': (1000, 10000, 100000)\n",
    "    }\n",
    "\n",
    "grid_search = GridSearchCV(p, parameters, n_jobs=1, verbose=1, cv=10)\n",
    "\n",
    "grid_search.fit(fixed_text, fixed_target)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
